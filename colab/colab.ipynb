{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "j4LMv5UbDtWH",
        "outputId": "6e88f67e-d283-4416-b7f0-4899c85073b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "base_path = '/content/drive/My Drive/sod'\n",
        "sys.path.append(base_path + '/BBS-Net')\n",
        "\n",
        "import shutil\n",
        "!mkdir -p /content/dataset\n",
        "cur_path = '/content/dataset/'\n",
        "shutil.copytree(base_path + '/dataset', cur_path, dirs_exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e94ypbPvJAo3"
      },
      "source": [
        "# Extract dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vmxHNGwGRVk"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "extract_to = cur_path\n",
        "\n",
        "zip_path = cur_path + 'test_in_train.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "zip_path = cur_path + 'RGBD_for_train.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "zip_path = cur_path + 'RGBD_for_test.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tURgLQdugHSA"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp0x4oEXgFTp",
        "outputId": "c3a23c49-1d02-4583-8eeb-1f47cc10035b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (5.29.5)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.4\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-VyeLsMdyPD",
        "outputId": "716cdadd-bb45-491e-f90c-888ef7cd92d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 173MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load model from  /content/drive/My Drive/sod/BBS-Net/BBSNet_cpts/BBSNet_epoch_best.pth\n",
            "load data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from BBSNet_train import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7zUI4W2vyl5",
        "outputId": "9b61a563-18f8-4094-b283-c63cfa0f73c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start train...\n",
            "2025-08-14 11:48:32.581967 Epoch [001/200], Step [0001/0729], Loss1: 0.1051 Loss2: 0.0690\n",
            "2025-08-14 11:51:29.060770 Epoch [001/200], Step [0100/0729], Loss1: 0.0656 Loss2: 0.0407\n",
            "2025-08-14 11:54:35.878083 Epoch [001/200], Step [0200/0729], Loss1: 0.0935 Loss2: 0.0653\n",
            "2025-08-14 11:57:42.563195 Epoch [001/200], Step [0300/0729], Loss1: 0.2743 Loss2: 0.2359\n",
            "2025-08-14 12:00:49.062857 Epoch [001/200], Step [0400/0729], Loss1: 0.1560 Loss2: 0.1396\n",
            "2025-08-14 12:03:55.542885 Epoch [001/200], Step [0500/0729], Loss1: 0.0437 Loss2: 0.0353\n",
            "2025-08-14 12:07:02.044936 Epoch [001/200], Step [0600/0729], Loss1: 0.1093 Loss2: 0.0977\n",
            "2025-08-14 12:10:08.525949 Epoch [001/200], Step [0700/0729], Loss1: 0.0630 Loss2: 0.0542\n",
            "2025-08-14 12:11:06.416847 Epoch [001/200], Step [0729/0729], Loss1: 0.0268 Loss2: 0.0249\n",
            "Epoch: 1 MAE: 0.05976463854312897 ####  bestMAE: 1 bestEpoch: 0\n",
            "2025-08-14 12:14:07.154614 Epoch [002/200], Step [0001/0729], Loss1: 0.0978 Loss2: 0.0771\n",
            "2025-08-14 12:17:11.667020 Epoch [002/200], Step [0100/0729], Loss1: 0.0645 Loss2: 0.0532\n",
            "2025-08-14 12:20:18.182959 Epoch [002/200], Step [0200/0729], Loss1: 0.0575 Loss2: 0.0385\n",
            "2025-08-14 12:23:24.777412 Epoch [002/200], Step [0300/0729], Loss1: 0.1610 Loss2: 0.1006\n",
            "2025-08-14 12:26:31.292464 Epoch [002/200], Step [0400/0729], Loss1: 0.0682 Loss2: 0.0559\n",
            "2025-08-14 12:29:37.733321 Epoch [002/200], Step [0500/0729], Loss1: 0.0812 Loss2: 0.0682\n",
            "2025-08-14 12:32:44.156699 Epoch [002/200], Step [0600/0729], Loss1: 0.0537 Loss2: 0.0366\n",
            "2025-08-14 12:35:50.608878 Epoch [002/200], Step [0700/0729], Loss1: 0.0944 Loss2: 0.0783\n",
            "2025-08-14 12:36:43.703306 Epoch [002/200], Step [0729/0729], Loss1: 0.0754 Loss2: 0.0725\n",
            "Epoch: 2 MAE: 0.056095242500305176 ####  bestMAE: 0.05976463854312897 bestEpoch: 0\n",
            "best epoch:2\n",
            "2025-08-14 12:39:48.363758 Epoch [003/200], Step [0001/0729], Loss1: 0.0752 Loss2: 0.0673\n",
            "2025-08-14 12:42:53.177971 Epoch [003/200], Step [0100/0729], Loss1: 0.0597 Loss2: 0.0416\n",
            "2025-08-14 12:45:59.624994 Epoch [003/200], Step [0200/0729], Loss1: 0.0438 Loss2: 0.0385\n",
            "2025-08-14 12:49:06.071796 Epoch [003/200], Step [0300/0729], Loss1: 0.1234 Loss2: 0.1525\n",
            "2025-08-14 12:52:12.540800 Epoch [003/200], Step [0400/0729], Loss1: 0.2287 Loss2: 0.1852\n",
            "2025-08-14 12:55:19.071886 Epoch [003/200], Step [0500/0729], Loss1: 0.1069 Loss2: 0.0887\n",
            "2025-08-14 12:58:25.514529 Epoch [003/200], Step [0600/0729], Loss1: 0.0674 Loss2: 0.0521\n",
            "2025-08-14 13:01:31.986028 Epoch [003/200], Step [0700/0729], Loss1: 0.2094 Loss2: 0.1885\n",
            "2025-08-14 13:02:25.064013 Epoch [003/200], Step [0729/0729], Loss1: 0.0401 Loss2: 0.0370\n",
            "Epoch: 3 MAE: 0.054135460406541824 ####  bestMAE: 0.056095242500305176 bestEpoch: 2\n",
            "best epoch:3\n",
            "2025-08-14 13:05:22.274123 Epoch [004/200], Step [0001/0729], Loss1: 0.0929 Loss2: 0.0716\n",
            "2025-08-14 13:08:27.729993 Epoch [004/200], Step [0100/0729], Loss1: 0.0624 Loss2: 0.0501\n",
            "2025-08-14 13:11:34.500171 Epoch [004/200], Step [0200/0729], Loss1: 0.0705 Loss2: 0.0524\n",
            "2025-08-14 13:14:41.274220 Epoch [004/200], Step [0300/0729], Loss1: 0.1069 Loss2: 0.1129\n",
            "2025-08-14 13:17:47.972730 Epoch [004/200], Step [0400/0729], Loss1: 0.1502 Loss2: 0.1386\n",
            "2025-08-14 13:20:54.656975 Epoch [004/200], Step [0500/0729], Loss1: 0.0439 Loss2: 0.0351\n",
            "2025-08-14 13:24:01.355266 Epoch [004/200], Step [0600/0729], Loss1: 0.0444 Loss2: 0.0352\n",
            "2025-08-14 13:27:08.270254 Epoch [004/200], Step [0700/0729], Loss1: 0.0512 Loss2: 0.0415\n",
            "2025-08-14 13:28:01.328625 Epoch [004/200], Step [0729/0729], Loss1: 0.0597 Loss2: 0.0540\n",
            "Epoch: 4 MAE: 0.04335121065378189 ####  bestMAE: 0.054135460406541824 bestEpoch: 3\n",
            "best epoch:4\n",
            "2025-08-14 13:31:03.217437 Epoch [005/200], Step [0001/0729], Loss1: 0.0803 Loss2: 0.0680\n",
            "2025-08-14 13:34:08.665448 Epoch [005/200], Step [0100/0729], Loss1: 0.1888 Loss2: 0.1788\n",
            "2025-08-14 13:37:15.410738 Epoch [005/200], Step [0200/0729], Loss1: 0.0971 Loss2: 0.0878\n",
            "2025-08-14 13:40:21.854867 Epoch [005/200], Step [0300/0729], Loss1: 0.0441 Loss2: 0.0311\n",
            "2025-08-14 13:43:28.276276 Epoch [005/200], Step [0400/0729], Loss1: 0.0602 Loss2: 0.0399\n",
            "2025-08-14 13:46:34.724472 Epoch [005/200], Step [0500/0729], Loss1: 0.0795 Loss2: 0.0503\n",
            "2025-08-14 13:49:41.215300 Epoch [005/200], Step [0600/0729], Loss1: 0.1136 Loss2: 0.0648\n",
            "2025-08-14 13:52:47.930078 Epoch [005/200], Step [0700/0729], Loss1: 0.0975 Loss2: 0.0928\n",
            "2025-08-14 13:53:41.286544 Epoch [005/200], Step [0729/0729], Loss1: 0.0348 Loss2: 0.0197\n",
            "Epoch: 5 MAE: 0.05225205793976784 ####  bestMAE: 0.04335121065378189 bestEpoch: 4\n",
            "2025-08-14 13:56:35.087846 Epoch [006/200], Step [0001/0729], Loss1: 0.0796 Loss2: 0.0705\n",
            "2025-08-14 13:59:39.752332 Epoch [006/200], Step [0100/0729], Loss1: 0.0611 Loss2: 0.0464\n",
            "2025-08-14 14:02:46.911281 Epoch [006/200], Step [0200/0729], Loss1: 0.0562 Loss2: 0.0427\n",
            "2025-08-14 14:05:53.727757 Epoch [006/200], Step [0300/0729], Loss1: 0.0683 Loss2: 0.0501\n",
            "2025-08-14 14:09:00.882599 Epoch [006/200], Step [0400/0729], Loss1: 0.0943 Loss2: 0.0754\n",
            "2025-08-14 14:12:07.642834 Epoch [006/200], Step [0500/0729], Loss1: 0.0715 Loss2: 0.0486\n",
            "2025-08-14 14:15:14.754355 Epoch [006/200], Step [0600/0729], Loss1: 0.1693 Loss2: 0.1107\n",
            "2025-08-14 14:18:21.727450 Epoch [006/200], Step [0700/0729], Loss1: 0.0790 Loss2: 0.0526\n",
            "2025-08-14 14:19:14.841953 Epoch [006/200], Step [0729/0729], Loss1: 0.8139 Loss2: 0.8857\n",
            "Epoch: 6 MAE: 0.0491362102329731 ####  bestMAE: 0.04335121065378189 bestEpoch: 4\n",
            "2025-08-14 14:22:04.256817 Epoch [007/200], Step [0001/0729], Loss1: 0.0563 Loss2: 0.0395\n",
            "2025-08-14 14:25:08.927968 Epoch [007/200], Step [0100/0729], Loss1: 0.0906 Loss2: 0.0690\n",
            "2025-08-14 14:28:15.496949 Epoch [007/200], Step [0200/0729], Loss1: 0.0606 Loss2: 0.0483\n",
            "2025-08-14 14:31:22.141836 Epoch [007/200], Step [0300/0729], Loss1: 0.0437 Loss2: 0.0340\n",
            "2025-08-14 14:34:28.712514 Epoch [007/200], Step [0400/0729], Loss1: 0.0853 Loss2: 0.0620\n",
            "2025-08-14 14:37:35.680007 Epoch [007/200], Step [0500/0729], Loss1: 0.1113 Loss2: 0.1066\n",
            "2025-08-14 14:40:42.451317 Epoch [007/200], Step [0600/0729], Loss1: 0.1138 Loss2: 0.0804\n",
            "2025-08-14 14:43:49.595376 Epoch [007/200], Step [0700/0729], Loss1: 0.1007 Loss2: 0.1040\n",
            "2025-08-14 14:44:42.735755 Epoch [007/200], Step [0729/0729], Loss1: 0.3731 Loss2: 0.2422\n",
            "Epoch: 7 MAE: 0.055768679827451706 ####  bestMAE: 0.04335121065378189 bestEpoch: 4\n",
            "2025-08-14 14:47:33.907825 Epoch [008/200], Step [0001/0729], Loss1: 0.0947 Loss2: 0.1114\n",
            "2025-08-14 14:50:38.978208 Epoch [008/200], Step [0100/0729], Loss1: 0.0647 Loss2: 0.0587\n",
            "2025-08-14 14:53:45.484484 Epoch [008/200], Step [0200/0729], Loss1: 0.1141 Loss2: 0.1097\n",
            "2025-08-14 14:56:52.122650 Epoch [008/200], Step [0300/0729], Loss1: 0.0610 Loss2: 0.0463\n",
            "2025-08-14 14:59:58.568983 Epoch [008/200], Step [0400/0729], Loss1: 0.0771 Loss2: 0.0660\n",
            "2025-08-14 15:03:05.391966 Epoch [008/200], Step [0500/0729], Loss1: 0.0649 Loss2: 0.0493\n",
            "2025-08-14 15:06:12.377377 Epoch [008/200], Step [0600/0729], Loss1: 0.0736 Loss2: 0.0555\n",
            "2025-08-14 15:09:19.230242 Epoch [008/200], Step [0700/0729], Loss1: 0.1183 Loss2: 0.0913\n",
            "2025-08-14 15:10:12.402275 Epoch [008/200], Step [0729/0729], Loss1: 0.0267 Loss2: 0.0178\n",
            "Epoch: 8 MAE: 0.053609542548656464 ####  bestMAE: 0.04335121065378189 bestEpoch: 4\n",
            "2025-08-14 15:13:02.438843 Epoch [009/200], Step [0001/0729], Loss1: 0.0354 Loss2: 0.0261\n",
            "2025-08-14 15:16:07.614837 Epoch [009/200], Step [0100/0729], Loss1: 0.2193 Loss2: 0.2824\n",
            "2025-08-14 15:19:14.758698 Epoch [009/200], Step [0200/0729], Loss1: 0.0554 Loss2: 0.0419\n",
            "2025-08-14 15:22:21.581901 Epoch [009/200], Step [0300/0729], Loss1: 0.0750 Loss2: 0.0483\n",
            "2025-08-14 15:25:28.583167 Epoch [009/200], Step [0400/0729], Loss1: 0.1003 Loss2: 0.0876\n",
            "2025-08-14 15:28:35.049530 Epoch [009/200], Step [0500/0729], Loss1: 0.0753 Loss2: 0.0578\n",
            "2025-08-14 15:31:41.629538 Epoch [009/200], Step [0600/0729], Loss1: 0.1627 Loss2: 0.1681\n",
            "2025-08-14 15:34:48.218457 Epoch [009/200], Step [0700/0729], Loss1: 0.0979 Loss2: 0.0775\n",
            "2025-08-14 15:35:41.448380 Epoch [009/200], Step [0729/0729], Loss1: 0.7037 Loss2: 0.5208\n",
            "Epoch: 9 MAE: 0.05593638867139816 ####  bestMAE: 0.04335121065378189 bestEpoch: 4\n",
            "2025-08-14 15:38:34.175890 Epoch [010/200], Step [0001/0729], Loss1: 0.1124 Loss2: 0.0872\n",
            "2025-08-14 15:41:38.801706 Epoch [010/200], Step [0100/0729], Loss1: 0.0973 Loss2: 0.0695\n",
            "2025-08-14 15:44:45.609860 Epoch [010/200], Step [0200/0729], Loss1: 0.0346 Loss2: 0.0235\n",
            "2025-08-14 15:47:52.048272 Epoch [010/200], Step [0300/0729], Loss1: 0.1070 Loss2: 0.0939\n",
            "2025-08-14 15:50:58.525370 Epoch [010/200], Step [0400/0729], Loss1: 0.1167 Loss2: 0.1202\n",
            "2025-08-14 15:54:05.024457 Epoch [010/200], Step [0500/0729], Loss1: 0.1418 Loss2: 0.1026\n",
            "2025-08-14 15:57:11.554369 Epoch [010/200], Step [0600/0729], Loss1: 0.0580 Loss2: 0.0404\n",
            "2025-08-14 16:00:18.057188 Epoch [010/200], Step [0700/0729], Loss1: 0.0629 Loss2: 0.0522\n",
            "2025-08-14 16:01:11.160829 Epoch [010/200], Step [0729/0729], Loss1: 0.0510 Loss2: 0.0422\n",
            "Epoch: 10 MAE: 0.048478178679943085 ####  bestMAE: 0.04335121065378189 bestEpoch: 4\n",
            "2025-08-14 16:04:09.362126 Epoch [011/200], Step [0001/0729], Loss1: 0.0871 Loss2: 0.0622\n",
            "2025-08-14 16:07:13.864662 Epoch [011/200], Step [0100/0729], Loss1: 0.0756 Loss2: 0.0503\n",
            "2025-08-14 16:10:20.383313 Epoch [011/200], Step [0200/0729], Loss1: 0.0697 Loss2: 0.0573\n",
            "2025-08-14 16:13:26.879554 Epoch [011/200], Step [0300/0729], Loss1: 0.0573 Loss2: 0.0425\n",
            "2025-08-14 16:16:33.318598 Epoch [011/200], Step [0400/0729], Loss1: 0.1888 Loss2: 0.1901\n",
            "2025-08-14 16:19:39.798815 Epoch [011/200], Step [0500/0729], Loss1: 0.0666 Loss2: 0.0429\n",
            "2025-08-14 16:22:46.360963 Epoch [011/200], Step [0600/0729], Loss1: 0.0684 Loss2: 0.0656\n",
            "2025-08-14 16:25:52.872830 Epoch [011/200], Step [0700/0729], Loss1: 0.0245 Loss2: 0.0187\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}